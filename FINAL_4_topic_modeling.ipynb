{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive visualisation for evaluation of LDA model \n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon2017_string=pd.read_pickle('../amazon2017_string.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung=amazon2017_string[amazon2017_string.brand == 'Samsung']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTORS :Count vectorizer & Tf-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-Words Model We cannot work with text directly when using machine learning algorithms.\n",
    "Instead, we need to convert the text to numbers. = > CountVectorizer\n",
    "\n",
    "The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "Create an instance of the CountVectorizer class.\n",
    "Call the fit() function in order to learn a vocabulary from one or more documents.\n",
    "Call the transform() function on one or more documents as needed to encode each as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we can apply LDA or NMF, we need to create vocabulary of all the words in our data, \n",
    "# vectorized matrix of the vocabulary.\n",
    "\n",
    "# COUNTVECTORIZER\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, strip_accents='ascii', stop_words='english')\n",
    "doc_term_matrix_cv = count_vectorizer.fit_transform(samsung.text_processed) # vocabulary encoded into vectors with countvectorizer\n",
    "\n",
    "# IF-IDF VECTORIZER\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, strip_accents='ascii', stop_words=\"english\")\n",
    "matrix_tfidfvect = tfidf_vectorizer.fit_transform(samsung.text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the vocabulary based on vectorizer method\n",
    "def print_vocabulary(vectorizer_method):\n",
    "    list_vocab=list(vectorizer_method.vocabulary_.items())\n",
    "    \n",
    "    list_vocab.sort(reverse=True) #sort in reverse order\n",
    "    print('Descending order is',list_vocab[:20])\n",
    "    \n",
    "def print_info(matrix_entry):\n",
    "    shape_matrix=matrix_entry.shape # print total number of features\n",
    "    arr_matrix=matrix_entry.toarray() # array representation of the matrix\n",
    "    return(print(shape_matrix), print(arr_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descending order is [('zte', 10555), ('zooming', 10554), ('zoomed', 10553), ('zoom', 10552), ('zones', 10551), ('zone', 10550), ('zona', 10549), ('zombie', 10548), ('zmax', 10547), ('zizo', 10546), ('zippier', 10545), ('zipcode', 10544), ('zip', 10543), ('zilch', 10542), ('zerolemon', 10541), ('zero', 10540), ('zenfone', 10539), ('zen', 10538), ('zbfatima', 10537), ('yrs', 10536)]\n",
      "\n",
      "Descending order is [('zte', 10555), ('zooming', 10554), ('zoomed', 10553), ('zoom', 10552), ('zones', 10551), ('zone', 10550), ('zona', 10549), ('zombie', 10548), ('zmax', 10547), ('zizo', 10546), ('zippier', 10545), ('zipcode', 10544), ('zip', 10543), ('zilch', 10542), ('zerolemon', 10541), ('zero', 10540), ('zenfone', 10539), ('zen', 10538), ('zbfatima', 10537), ('yrs', 10536)]\n"
     ]
    }
   ],
   "source": [
    "print_vocabulary(count_vectorizer)\n",
    "print()\n",
    "print_vocabulary(tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29505, 10556)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "(29505, 10556)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_info(doc_term_matrix_cv)\n",
    "print()\n",
    "print_info(matrix_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abd</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>...</th>\n",
       "      <th>zizo</th>\n",
       "      <th>zmax</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zona</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29504</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 10556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaaaa  aback  abajo  abandon  abandoning  abd  abierto  abilities  \\\n",
       "29503      0      0      0        0           0    0        0          0   \n",
       "29504      0      0      0        0           0    0        0          0   \n",
       "\n",
       "       ability  abit  ...  zizo  zmax  zombie  zona  zone  zones  zoom  \\\n",
       "29503        0     0  ...     0     0       0     0     0      0     0   \n",
       "29504        0     0  ...     0     0       0     0     0      0     0   \n",
       "\n",
       "       zoomed  zooming  zte  \n",
       "29503       0        0    0  \n",
       "29504       0        0    0  \n",
       "\n",
       "[2 rows x 10556 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "pd.DataFrame(doc_term_matrix_cv.todense(), columns=count_vectorizer.get_feature_names()).tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abd</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>...</th>\n",
       "      <th>zizo</th>\n",
       "      <th>zmax</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zona</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 10556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaaaa  aback  abajo  abandon  abandoning  abd  abierto  abilities  \\\n",
       "29503    0.0    0.0    0.0      0.0         0.0  0.0      0.0        0.0   \n",
       "29504    0.0    0.0    0.0      0.0         0.0  0.0      0.0        0.0   \n",
       "\n",
       "       ability  abit  ...  zizo  zmax  zombie  zona  zone  zones  zoom  \\\n",
       "29503      0.0   0.0  ...   0.0   0.0     0.0   0.0   0.0    0.0   0.0   \n",
       "29504      0.0   0.0  ...   0.0   0.0     0.0   0.0   0.0    0.0   0.0   \n",
       "\n",
       "       zoomed  zooming  zte  \n",
       "29503     0.0      0.0  0.0  \n",
       "29504     0.0      0.0  0.0  \n",
       "\n",
       "[2 rows x 10556 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "pd.DataFrame(matrix_tfidfvect.todense(), columns=tfidf_vectorizer.get_feature_names()).tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Sparsicity\n",
    "Sparsicity is the percentage of non-zero datapoints in the document-word matrix, that is data_vectorized.\n",
    "\n",
    "Since most cells in this matrix will be zero, the question is what percentage of cells contain non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity - percentage of cells containing non-zero values: 0.14354379149358376 %\n"
     ]
    }
   ],
   "source": [
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity - percentage of cells containing non-zero values:\", ((doc_term_matrix_cv.todense() > 0).sum()/doc_term_matrix_cv.todense().size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Topic Model : Latent Dirichlet Allocation (LDA)  &  Non-Negative Matrix Factorization (NMF)\n",
    "\n",
    "We have everything required to train the LDA model. In addition to the corpus and dictionary, need to provide the number of topics as well.\n",
    "tried n of topics from 3 to 10, then after GridSerachCV - found out 5-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised machine learning. In this project only LDA and NMF models are used. There are however other existing ways (not studied here)\n",
    "\n",
    "- LSA matrix decomposition\n",
    "    - Latent semantic analysis\n",
    "\n",
    "- Probabilistic inference\n",
    "    - pLSA probabilistic LSA\n",
    "    - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_components = 5\n",
    "no_top_words = 20\n",
    "# Function to print the topics\n",
    "def display_topics(model, feature_names, no_top_words):    \n",
    "    for topic_idx, topic in enumerate(model.components_):        \n",
    "        print(\"Topic %d:\" % (topic_idx))       \n",
    "        print (\",\".join([feature_names[i]                       \n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both models on CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0290496 , 0.02891718, 0.12401535, 0.02873973, 0.78927814],\n",
       "       [0.26897001, 0.06731604, 0.52766002, 0.06730662, 0.0687473 ],\n",
       "       [0.04059865, 0.04085262, 0.83820562, 0.04029031, 0.0400528 ],\n",
       "       ...,\n",
       "       [0.02522593, 0.02515986, 0.89893111, 0.02542949, 0.02525361],\n",
       "       [0.02881289, 0.02878882, 0.88484204, 0.02858289, 0.02897336],\n",
       "       [0.54766502, 0.42365121, 0.00957158, 0.00955348, 0.00955872]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LDA_cv = LatentDirichletAllocation(n_components=number_components)\n",
    "model_LDA_cv.fit_transform(doc_term_matrix_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.12213476, 0.        ],\n",
       "       [0.0006574 , 0.00366784, 0.        , 0.00460132, 0.00704501],\n",
       "       [0.        , 0.01843895, 0.0082014 , 0.00117792, 0.01674442],\n",
       "       ...,\n",
       "       [0.03143396, 0.07610508, 0.        , 0.12125006, 0.        ],\n",
       "       [0.        , 0.1595353 , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.17469433]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NMF_cv = NMF(n_components=number_components)\n",
    "model_NMF_cv.fit_transform(doc_term_matrix_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT VECTORIZER. TWO MODELS\n",
      "LDA MODEL TOPICS\n",
      "Topic 0:\n",
      "new,sim,card,unlocked,came,charger,like,box,att,brand,works,verizon,great,good,samsung,condition,refurbished,used,tmobile,got\n",
      "Topic 1:\n",
      "work,buy,samsung,verizon,return,bought,unlocked,working,dont,months,seller,use,got,att,time,star,amazon,product,service,new\n",
      "Topic 2:\n",
      "great,good,stars,works,love,new,price,like,product,excellent,condition,perfect,happy,far,nice,buy,awesome,fast,quality,looks\n",
      "Topic 3:\n",
      "samsung,apps,android,iphone,gb,use,app,excelente,storage,telefono,bixby,apple,google,memory,fingerprint,galaxy,sd,bueno,buen,using\n",
      "Topic 4:\n",
      "battery,screen,life,good,camera,like,note,use,samsung,great,really,dont,im,better,time,ive,galaxy,fast,day,charge\n",
      "Done in 0.039s.\n",
      "\n",
      "NMF MODEL TOPICS\n",
      "Topic 0:\n",
      "samsung,note,screen,galaxy,camera,use,best,really,love,time,better,case,device,gb,buy,pen,fast,im,features,edge\n",
      "Topic 1:\n",
      "great,works,price,love,stars,condition,fast,product,far,camera,quality,deal,came,value,buy,perfect,looks,awesome,easy,excellent\n",
      "Topic 2:\n",
      "apps,screen,iphone,use,app,like,set,dont,android,pro,using,ive,button,im,used,better,big,time,way,work\n",
      "Topic 3:\n",
      "battery,good,life,charge,use,day,fast,price,really,far,camera,screen,hours,time,charger,charging,quality,bad,dont,buy\n",
      "Topic 4:\n",
      "new,like,sim,card,verizon,unlocked,brand,att,work,came,works,refurbished,box,buy,looks,seller,charger,got,im,amazon\n",
      "Done in 0.054s.\n"
     ]
    }
   ],
   "source": [
    "print('COUNT VECTORIZER. TWO MODELS')\n",
    "t0 = time.time()\n",
    "print('LDA MODEL TOPICS')\n",
    "display_topics(model_LDA_cv, count_vectorizer.get_feature_names(), no_top_words)\n",
    "print(\"Done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print()\n",
    "\n",
    "print('NMF MODEL TOPICS')\n",
    "display_topics(model_NMF_cv, count_vectorizer.get_feature_names(), no_top_words)\n",
    "print(\"Done in %0.3fs.\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both model on Tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LDA_tf= LatentDirichletAllocation(n_components=number_components)\n",
    "model_LDA_tf.fit(matrix_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.07232935, 0.        , 0.        ],\n",
       "       [0.        , 0.12786186, 0.        , 0.00521772, 0.        ],\n",
       "       [0.01989308, 0.001946  , 0.00816752, 0.02174253, 0.        ],\n",
       "       ...,\n",
       "       [0.02792951, 0.        , 0.10040305, 0.00850954, 0.00240272],\n",
       "       [0.05990107, 0.        , 0.        , 0.00355847, 0.00077252],\n",
       "       [0.        , 0.        , 0.        , 0.03956967, 0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NMF_tf = NMF(n_components=number_components)\n",
    "model_NMF_tf.fit_transform(matrix_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF VECTORIZER. TWO MODELS\n",
      "LDA MODEL\n",
      "Topic 0:\n",
      "excelente,stars,loves,nice,ok,bueno,awesome,gift,telefono,buen,bien,producto,battery,great,husband,life,perfecto,wife,celular,llego\n",
      "Topic 1:\n",
      "battery,screen,great,new,good,samsung,like,charger,buy,dont,charge,use,life,got,months,im,note,work,bought,time\n",
      "Topic 2:\n",
      "great,stars,love,good,works,new,like,excellent,perfect,product,price,condition,happy,far,brand,looks,expected,best,described,nice\n",
      "Topic 3:\n",
      "unlocked,work,verizon,star,att,sim,locked,tmobile,network,card,sprint,carrier,return,use,compatible,buy,service,activate,mobile,unlock\n",
      "Topic 4:\n",
      "good,easy,use,stars,great,thanks,value,nice,quality,liked,love,mom,personal,product,price,far,bad,money,set,timely\n",
      "Done in 0.040s.\n",
      "\n",
      "NMF MODEL\n",
      "Topic 0:\n",
      "great,works,price,product,condition,value,buy,awesome,deal,quality,fast,far,purchase,camera,service,described,problems,loves,shipping,issues\n",
      "Topic 1:\n",
      "stars,excellent,nice,perfect,ok,thanks,works,expected,excelente,product,happy,condition,advertised,like,working,excelent,thank,fine,described,loves\n",
      "Topic 2:\n",
      "good,price,product,far,quality,value,works,deal,really,battery,condition,nice,working,buy,money,camera,fast,pretty,life,overall\n",
      "Topic 3:\n",
      "new,like,battery,brand,works,unlocked,looks,screen,work,samsung,came,buy,use,perfect,sim,happy,condition,life,card,refurbished\n",
      "Topic 4:\n",
      "love,awesome,note,best,samsung,amazing,absolutely,perfect,thank,galaxy,camera,easy,fast,features,quality,size,buy,ive,im,color\n",
      "Done in 0.056s.\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF VECTORIZER. TWO MODELS')\n",
    "t0 = time.time()\n",
    "print('LDA MODEL')\n",
    "display_topics(model_LDA_tf, tfidf_vectorizer.get_feature_names(), no_top_words)\n",
    "print(\"Done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print()\n",
    "\n",
    "print('NMF MODEL')\n",
    "display_topics(model_NMF_tf, tfidf_vectorizer.get_feature_names(), no_top_words)\n",
    "print(\"Done in %0.3fs.\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA vizualisation on both count and tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleouetd01\\anaconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1138829557992961844921042155\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1138829557992961844921042155_data = {\"mdsDat\": {\"x\": [0.18063370307375914, 0.035948213143569704, 0.04242855589126872, 0.004294929793782311, -0.2633054019023797], \"y\": [-0.05744513054920847, 0.10281904836456285, -0.10741109409151331, 0.10303569750961213, -0.04099852123345329], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [40.504021913117896, 19.11285465226706, 18.05981043647126, 11.862466888491225, 10.460846109652566]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [1358.0, 1606.0, 1281.0, 831.0, 771.0, 409.0, 776.0, 517.0, 607.0, 150.0, 670.0, 276.0, 307.0, 388.0, 490.0, 427.0, 264.0, 302.0, 365.0, 282.0, 291.0, 300.0, 103.0, 145.0, 202.0, 195.0, 350.0, 250.0, 312.0, 233.0, 132.52702404629892, 80.28682018164002, 76.02106717997985, 56.725166787269565, 53.7014591532347, 47.949937505343115, 47.0473324968247, 42.81123448657419, 37.06149660168575, 78.17836700309884, 40.12222305459614, 35.39785633201973, 31.53942018643991, 47.796705831784145, 30.572060242373038, 27.74428250312363, 26.83778401995278, 25.994404331713614, 118.85010018204605, 24.991487989237566, 24.70325678510716, 23.487774641878328, 24.236485043512904, 22.745329550397315, 21.973508181636426, 49.990975894517646, 22.023688574343254, 56.41998837273156, 20.344373724377245, 21.902251145754132, 122.0893720353964, 95.32714335116962, 49.519419487943885, 45.33769229132729, 260.5121418038487, 72.91622368413552, 234.3654072738176, 75.67356410563052, 71.91466610086918, 75.92751816191688, 44.079044025431074, 154.49007900797457, 84.16271563854221, 353.92675323584643, 241.75132038509972, 142.62842369310576, 216.06284545548883, 78.00656805858547, 95.97252501304895, 98.94773872399124, 79.70791439647124, 73.0633759993235, 307.2220481465963, 65.22753589944378, 133.98187138844108, 144.56522650535007, 79.78961828973522, 144.7360840372904, 165.0324648934038, 85.86048166939565, 102.72995687847119, 183.94816011894983, 187.5524369476961, 150.49774643658915, 106.02425410007199, 173.80871832170845, 195.19402907123919, 126.06230416103722, 136.35167246915896, 139.33570675659587, 159.99174792501552, 126.2440311787183, 154.05327553924104, 108.21183055729063, 109.36343611620285, 112.66125130250957, 110.7612520015641, 115.48311578751132, 29.31292176501399, 77.91292879663523, 12.292291561329826, 29.659595199147816, 10.004501550079858, 11.999828756227334, 17.337362320489653, 9.18228923733044, 22.065324098301712, 48.421004612770865, 8.330165074051962, 26.032648939605842, 7.843897864418546, 7.615455522615356, 41.239788039431126, 7.367225299317704, 6.87882683041081, 7.2978986533294234, 20.335634246238985, 7.925522707017129, 6.510016406166738, 32.529930759763076, 6.28365412732491, 7.599012225570894, 8.243440453314948, 5.613637281792219, 5.623075127737033, 5.462015022640105, 5.436039898838846, 5.379583733154888, 21.33166216050589, 9.69823192069525, 63.56472596360231, 31.814415144363505, 9.410022245825742, 25.211943668937156, 149.16898212003557, 205.49317882778436, 169.7732043689281, 75.39087273720556, 32.05097395655007, 458.60468039379, 46.54552080976541, 67.90707779117267, 29.480030230751836, 21.530028512011853, 33.81674360435621, 155.4797255241036, 506.3722638312562, 91.1303008403619, 53.209682324587355, 182.42223456041995, 36.16179128160781, 98.46866035542699, 111.32346988791129, 110.87230413625173, 146.23568036955373, 109.77984004813595, 50.86647314436334, 167.76011799519242, 305.25502659179955, 114.38947531962637, 56.21215192461674, 100.35915702026784, 131.1887992439119, 150.8680432543489, 207.3507942496137, 114.12511859972471, 89.52789759422035, 69.96964476416589, 97.61672530292059, 70.66027934868552, 60.23007524473661, 69.53178237998779, 78.9382951374828, 68.19398960504807, 12.438266169950206, 14.089586886337003, 14.509920134611983, 8.58664373528791, 8.564992414369655, 20.286959456625127, 6.292472977396469, 5.712229018974339, 5.174922733151475, 4.483535018181224, 16.27726078641435, 10.058252620332736, 14.64110358040487, 6.149646621492782, 5.165169253139357, 3.6747946183347815, 229.55128484256414, 15.362576918842912, 3.702627354420093, 3.491000145000147, 20.746172778254678, 3.4712808597244287, 16.8921630081778, 4.647437467664947, 3.1993698629766416, 3.114407024763826, 3.1058376053912373, 15.897188769357832, 3.2043777919669454, 10.17286726436552, 208.59990707633392, 15.691548743295552, 19.393603920930136, 149.44115399915216, 21.02825156093005, 89.84519586427837, 17.729964787868063, 109.89445614302888, 24.327185896889834, 112.4268126470864, 488.8093138060833, 28.662383842565443, 72.13139032008975, 186.4581850765627, 121.279960812358, 198.31890314772403, 208.06319370521445, 132.2386679881542, 86.85418940921478, 341.276959622077, 155.6510268217341, 176.9357224492382, 136.28239583223936, 129.24351930397, 141.8882240736465, 343.1385098497292, 170.39011339716404, 127.05721798606848, 86.72938456709964, 89.17017518879008, 408.6866305648239, 146.33639428488343, 94.06985409487635, 156.9667168941144, 91.64034101523852, 247.2943895412118, 172.6532824539282, 98.02721474235288, 91.51558219695887, 28.439139374278724, 17.47121045491884, 10.417008702689476, 15.99373631711199, 11.123499628052409, 9.849454665386864, 6.531290496260324, 6.35348358172498, 6.0747892814898945, 6.094108368700688, 5.716954889463539, 5.945376480697173, 7.15543924599529, 9.616174810904585, 37.77806894796429, 5.188148147904728, 6.970458740912532, 4.6891515929681935, 4.739838689175184, 4.35470348164529, 11.837492848021796, 4.1814963241562, 4.069736032332505, 4.127134353019725, 4.099027065762422, 37.64320541371031, 9.010821567736938, 119.85258557155215, 8.877380474359768, 13.29272484122541, 39.7100130027162, 59.09380489287628, 15.471018441213655, 70.50154939625496, 14.35672131233337, 23.71681162710804, 41.3736142194692, 17.959601082469806, 19.17184676334348, 18.883206458734314, 109.60222672483543, 33.14577255459748, 85.42201454383247, 31.75447106773723, 25.223974740240905, 12.754819415937476, 120.35648828577534, 14.103213101584586, 42.827104235194305, 186.65962715707002, 139.86766046077867, 153.5058335050214, 75.57374165293874, 86.7448713855817, 94.07873865198879, 64.43361475244393, 277.3993607258655, 56.9295680841487, 99.85788186514026, 27.998454843120204, 148.92006507691318, 69.88681192626328, 40.68214940389071, 61.68091720271779, 46.101678366100835, 84.87932841852428, 64.1175490859024, 54.90861262584416, 54.343951877657844, 55.476361932155335, 72.35573180201929, 61.659832875704545, 58.87484368546293, 53.30278127251386, 47.30382781522745, 46.23077493951985, 149.557065619978, 103.02793294687764, 77.97009769996595, 71.19039185780647, 64.1284893388816, 63.18755883526395, 42.9429753447786, 40.15586564515426, 37.27554643178805, 36.251749621048525, 33.19999313549471, 26.36814592562778, 26.181145567305208, 25.60928288535197, 23.99958040950643, 21.815120690486847, 20.6586246713176, 20.09205268888943, 19.96517182811833, 19.899856669229646, 19.903377580458596, 19.469524197495346, 19.107795724206575, 17.770159342452764, 17.741351447672983, 16.87412535267998, 15.779270645679285, 15.80768251273264, 15.548265548751697, 15.48144127037902, 899.6472650579981, 19.975687448582057, 244.7702851884807, 159.56946159976127, 78.9926639733523, 58.76940230210948, 223.71685476739455, 527.0586505473548, 64.05239451208655, 141.48146456361792, 69.65901661403647, 270.74409560327166, 192.63818786075024, 189.7900855506854, 86.45083704115434, 95.93403360392237, 95.96278820395143, 95.26077539059851, 78.96294445913685, 57.05983499881247, 42.99635253696025, 43.186098606203046, 39.219585699240675, 40.37345381325419], \"Term\": [\"stars\", \"great\", \"good\", \"love\", \"new\", \"excellent\", \"works\", \"product\", \"battery\", \"excelente\", \"like\", \"brand\", \"awesome\", \"perfect\", \"price\", \"nice\", \"looks\", \"best\", \"condition\", \"star\", \"life\", \"working\", \"bueno\", \"loves\", \"easy\", \"described\", \"far\", \"camera\", \"fast\", \"expected\", \"locked\", \"compatible\", \"activate\", \"beware\", \"number\", \"gsm\", \"calling\", \"connect\", \"unable\", \"turn\", \"called\", \"carriers\", \"false\", \"stolen\", \"imei\", \"randomly\", \"message\", \"scam\", \"sprint\", \"shut\", \"prepaid\", \"advertising\", \"cards\", \"connection\", \"cdma\", \"hear\", \"wasted\", \"told\", \"texts\", \"unusable\", \"network\", \"calls\", \"help\", \"account\", \"verizon\", \"wifi\", \"att\", \"send\", \"refund\", \"tried\", \"google\", \"return\", \"defective\", \"unlocked\", \"sim\", \"tmobile\", \"card\", \"unlock\", \"wont\", \"carrier\", \"store\", \"waste\", \"work\", \"data\", \"doesnt\", \"charge\", \"returned\", \"didnt\", \"dont\", \"make\", \"disappointed\", \"use\", \"samsung\", \"got\", \"amazon\", \"buy\", \"battery\", \"seller\", \"time\", \"bought\", \"screen\", \"star\", \"new\", \"service\", \"months\", \"im\", \"charger\", \"like\", \"recognition\", \"fingerprint\", \"slim\", \"sensor\", \"amoled\", \"acts\", \"curved\", \"neat\", \"cameras\", \"reader\", \"wide\", \"scanner\", \"luv\", \"batery\", \"finger\", \"nicks\", \"facing\", \"surprisingly\", \"fragile\", \"mah\", \"movies\", \"print\", \"rough\", \"crisp\", \"slippery\", \"intuitive\", \"gorilla\", \"selfie\", \"vr\", \"brilliant\", \"sleek\", \"alright\", \"size\", \"face\", \"facial\", \"smooth\", \"amazing\", \"best\", \"camera\", \"beautiful\", \"cool\", \"love\", \"display\", \"iphone\", \"loving\", \"bigger\", \"lasts\", \"note\", \"good\", \"ok\", \"pictures\", \"screen\", \"decent\", \"better\", \"galaxy\", \"really\", \"samsung\", \"life\", \"big\", \"battery\", \"great\", \"far\", \"pretty\", \"quality\", \"price\", \"like\", \"stars\", \"nice\", \"fast\", \"ive\", \"works\", \"im\", \"features\", \"awesome\", \"new\", \"use\", \"grandson\", \"bang\", \"buck\", \"awsome\", \"responding\", \"charm\", \"doa\", \"defected\", \"exelent\", \"merchant\", \"hesitant\", \"prompt\", \"sooner\", \"likenew\", \"spanking\", \"teenage\", \"brand\", \"cosmetic\", \"evidence\", \"phoneno\", \"packaged\", \"bubbles\", \"dents\", \"splus\", \"vertical\", \"phonr\", \"greate\", \"performs\", \"awaiting\", \"appearance\", \"looks\", \"nervous\", \"mint\", \"described\", \"skeptical\", \"pleased\", \"marks\", \"perfectly\", \"flawless\", \"scratches\", \"new\", \"early\", \"looked\", \"working\", \"arrived\", \"came\", \"condition\", \"problems\", \"exactly\", \"like\", \"star\", \"happy\", \"refurbished\", \"issues\", \"purchase\", \"works\", \"far\", \"charger\", \"box\", \"fine\", \"great\", \"perfect\", \"worked\", \"buy\", \"expected\", \"good\", \"stars\", \"product\", \"screen\", \"likes\", \"penny\", \"meets\", \"met\", \"rocks\", \"fabulous\", \"extras\", \"satisfy\", \"grate\", \"lil\", \"starter\", \"schedule\", \"liking\", \"sweet\", \"personal\", \"brainer\", \"fiance\", \"figuring\", \"stylish\", \"hiccups\", \"exynos\", \"thankful\", \"unblocked\", \"pleasure\", \"attractive\", \"daughter\", \"inexpensive\", \"loves\", \"exceptional\", \"hoped\", \"recommended\", \"husband\", \"snapdragon\", \"wife\", \"sister\", \"budget\", \"smartphone\", \"favorite\", \"enjoying\", \"reasonable\", \"easy\", \"durable\", \"worth\", \"reliable\", \"lots\", \"sturdy\", \"life\", \"priced\", \"highly\", \"battery\", \"nice\", \"price\", \"value\", \"money\", \"quality\", \"recommend\", \"great\", \"features\", \"use\", \"expectations\", \"good\", \"best\", \"gift\", \"really\", \"need\", \"love\", \"excellent\", \"bought\", \"fast\", \"happy\", \"stars\", \"works\", \"like\", \"product\", \"new\", \"samsung\", \"excelente\", \"bueno\", \"telefono\", \"buen\", \"bien\", \"producto\", \"excelent\", \"perfecto\", \"celular\", \"llego\", \"funciona\", \"precio\", \"buena\", \"nuevo\", \"bateria\", \"camara\", \"calidad\", \"equipo\", \"pantalla\", \"rapido\", \"gusto\", \"compra\", \"recomiendo\", \"mejor\", \"tiempo\", \"gracias\", \"cargador\", \"si\", \"solo\", \"compre\", \"stars\", \"timely\", \"excellent\", \"awesome\", \"thanks\", \"delivery\", \"product\", \"great\", \"shipping\", \"perfect\", \"thank\", \"good\", \"works\", \"love\", \"expected\", \"fast\", \"nice\", \"price\", \"condition\", \"advertised\", \"satisfied\", \"value\", \"gift\", \"quality\"], \"Total\": [1358.0, 1606.0, 1281.0, 831.0, 771.0, 409.0, 776.0, 517.0, 607.0, 150.0, 670.0, 276.0, 307.0, 388.0, 490.0, 427.0, 264.0, 302.0, 365.0, 282.0, 291.0, 300.0, 103.0, 145.0, 202.0, 195.0, 350.0, 250.0, 312.0, 233.0, 133.26716068111858, 81.04418495620558, 76.76358695700348, 57.47750618026191, 54.46407339716498, 48.6951227395458, 47.78885482734028, 43.569581536208275, 37.80374276109882, 79.7942201009725, 40.9551705997393, 36.139129791365036, 32.2792157491609, 48.98920817863562, 31.34293240684384, 28.488732387233842, 27.580328757165802, 26.734546896932795, 122.31005706082239, 25.731773405518425, 25.451205766717568, 24.22837049377795, 25.013936929873385, 23.49182155317458, 22.713979427585972, 51.678625914682044, 22.773598404693463, 58.39646393832754, 21.089047222030363, 22.704738000812803, 126.82857783308275, 99.05722814612436, 51.44202101810156, 47.06036708861112, 278.88550914516395, 76.75461333944462, 257.34665147589806, 80.41000922133098, 76.43287285112933, 80.84247999770493, 46.18514897962827, 170.6375571674816, 91.18096708066959, 417.2235923957329, 283.2468862427941, 161.32989987528245, 259.4398439192657, 85.44221597392064, 108.04651326727225, 112.1945514930758, 88.04976863034832, 80.25849243358505, 433.0548337560116, 71.00052019332098, 181.33855421992317, 204.50292274277916, 93.51696992030156, 213.41505037951927, 265.8946584769112, 104.04202034311255, 139.5160394667365, 378.71711849943216, 442.3596698635598, 298.6507531806014, 159.30986978985845, 450.9202730379837, 607.1216005873925, 238.06076151975077, 292.01417522134335, 315.27130278677294, 443.92734586385694, 282.48384598178535, 771.321580226787, 188.8374985061204, 205.47680666434485, 273.77623238157895, 256.8471930716709, 670.7974282194554, 30.62008041243449, 82.15990255714772, 13.02846459843138, 31.573794449061314, 10.74447398305741, 12.888175920703322, 18.65433693172937, 9.916418577271543, 23.873675347019606, 52.52783720093985, 9.066396380435778, 28.464083655951857, 8.578211384868336, 8.355147546000884, 45.395507229196745, 8.111235733691805, 7.617275192342182, 8.094078197243672, 22.611736509696655, 8.827003769305898, 7.251175222905016, 36.307769696197106, 7.019649909040557, 8.503797771550088, 9.309482379067502, 6.349126263384571, 6.368823222748457, 6.199628995043073, 6.172905926312774, 6.115052372263383, 24.258531854265634, 11.03194475444746, 74.09043292517715, 37.269173859320084, 10.768229823026557, 30.766800181440594, 207.9927837534282, 302.5005022410903, 250.18374141419494, 105.14547994293947, 41.71270632389081, 831.9674183744899, 63.72987019721305, 99.92156768625713, 39.04601455587782, 27.409775173907562, 47.49057905998569, 291.9708854075772, 1281.6526797959914, 167.28722294981782, 86.14101050620896, 443.92734586385694, 55.617413303641385, 221.2222294853021, 266.30602443619233, 281.4604224442955, 442.3596698635598, 291.77836547524987, 89.63272105919077, 607.1216005873925, 1606.1041103203393, 350.0017659379467, 107.3752567299536, 300.2826554181349, 490.4401451159857, 670.7974282194554, 1358.4813650041299, 427.0204624403229, 312.18121532243225, 201.59692262744827, 776.6716014956027, 273.77623238157895, 145.62465636846034, 307.6503587219197, 771.321580226787, 378.71711849943216, 13.177930808903836, 15.010226324028531, 15.527032494623477, 9.34040001685875, 9.337826553332377, 22.51103955398299, 7.032644275172687, 6.448983031297153, 5.909487559075886, 5.246766400373207, 19.11229217977501, 11.832288578780934, 17.303040854986854, 7.271875968207854, 6.151070419545211, 4.412662848732298, 276.01007347372024, 18.56454233895256, 4.478697598926295, 4.228038395227214, 25.176424323859823, 4.223598251626689, 20.705225739318706, 5.697410083465267, 3.9428704819268114, 3.8495580916699437, 3.840377477102326, 19.664415688794687, 3.9672479815009756, 12.59599021245127, 264.43408819899423, 19.4787836242387, 24.271511004556938, 195.04029112111445, 26.754112350042753, 120.29907746234971, 22.57830316938796, 148.56031899298745, 31.63148090095963, 160.8048401669187, 771.321580226787, 37.796042963281195, 103.51534951648394, 300.4625926956716, 193.37076872926863, 344.0531400214112, 365.91840428127153, 220.05615416720153, 137.07596155636526, 670.7974282194554, 282.48384598178535, 339.02016371056146, 250.70268607447372, 235.24613007856485, 266.7472159968047, 776.6716014956027, 350.0017659379467, 256.8471930716709, 176.84927852244158, 184.73616569862665, 1606.1041103203393, 388.98498310363215, 210.76237875360152, 450.9202730379837, 233.79146070580623, 1281.6526797959914, 1358.4813650041299, 517.948552631982, 443.92734586385694, 29.175368402895213, 18.34989103445251, 11.144881816368853, 17.18796186739979, 11.997541084839536, 10.931576548435231, 7.267589392638422, 7.080748762715463, 6.799049658875766, 6.821661321970041, 6.448208446293732, 6.710723983716874, 8.097617315543665, 10.966235297348382, 43.12912293068628, 5.961656251632279, 8.09060872776756, 5.454104093608263, 5.518314206012386, 5.10921070657413, 13.90397264910129, 4.918982595483525, 4.799548541110549, 4.89914067664685, 4.867440563824879, 45.386469120189204, 10.929527070718198, 145.4660621520504, 10.785506263272003, 16.15330078279732, 48.92955420615736, 76.48276211526516, 19.19834307002106, 95.51098654597891, 18.213472125028076, 31.560418613327663, 60.184551401224745, 23.930928053549184, 26.002153178228102, 25.77423200271117, 202.94301714439558, 50.46312333744944, 162.3070201608547, 49.55275574204262, 39.483825965771956, 16.910739233367163, 291.77836547524987, 19.49206428261204, 83.5185351488106, 607.1216005873925, 427.0204624403229, 490.4401451159857, 190.22687167750016, 242.26497419507692, 300.2826554181349, 175.4610106413044, 1606.1041103203393, 145.62465636846034, 378.71711849943216, 49.96233722013554, 1281.6526797959914, 302.5005022410903, 113.6814036367517, 281.4604224442955, 153.99305761528046, 831.9674183744899, 409.11388088429936, 315.27130278677294, 312.18121532243225, 339.02016371056146, 1358.4813650041299, 776.6716014956027, 670.7974282194554, 517.948552631982, 771.321580226787, 442.3596698635598, 150.28187113176685, 103.75283966633607, 78.69474937007634, 71.91501189578284, 64.8530997650238, 63.912232745014485, 43.6691929866368, 40.880448953495424, 38.00054980522595, 36.9763417468843, 33.92458143218965, 27.092745247232855, 26.905722196886696, 26.333862331466012, 24.724161567854786, 22.548113534197867, 21.383201872719, 20.81675193352271, 20.689752590274672, 20.624435670482182, 20.63305192835679, 20.194109755936903, 19.83238442200089, 18.494875553206985, 18.46602717808815, 17.598722844327625, 16.503887204725213, 16.53773613212312, 16.272873977554003, 16.20707267416302, 1358.4813650041299, 21.733795469649156, 409.11388088429936, 307.6503587219197, 129.83830374915598, 88.94170250963974, 517.948552631982, 1606.1041103203393, 109.41522989408111, 388.98498310363215, 144.32948916983037, 1281.6526797959914, 776.6716014956027, 831.9674183744899, 233.79146070580623, 312.18121532243225, 427.0204624403229, 490.4401451159857, 365.91840428127153, 184.17103715002585, 157.0698971775226, 190.22687167750016, 113.6814036367517, 300.2826554181349], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8982, 0.8944, 0.894, 0.8906, 0.8897, 0.8883, 0.8881, 0.8862, 0.8839, 0.8833, 0.8832, 0.883, 0.8806, 0.8791, 0.8789, 0.8773, 0.8765, 0.8757, 0.8751, 0.8746, 0.8739, 0.8727, 0.8722, 0.8715, 0.8706, 0.8706, 0.8703, 0.8693, 0.8678, 0.8678, 0.8657, 0.8654, 0.8657, 0.8665, 0.8356, 0.8525, 0.8102, 0.8431, 0.8428, 0.841, 0.8571, 0.8044, 0.8237, 0.7392, 0.7454, 0.7806, 0.7208, 0.8127, 0.7853, 0.7781, 0.8042, 0.8098, 0.5605, 0.819, 0.6011, 0.5569, 0.745, 0.5154, 0.4268, 0.7117, 0.5977, 0.1816, 0.0457, 0.2184, 0.4966, -0.0496, -0.231, 0.268, 0.1422, 0.0872, -0.1168, 0.0984, -0.707, 0.347, 0.2731, 0.0158, 0.0627, -0.8556, 1.6112, 1.6017, 1.5966, 1.5923, 1.5835, 1.5834, 1.5816, 1.5779, 1.576, 1.5734, 1.5701, 1.5655, 1.5653, 1.5621, 1.5588, 1.5586, 1.5528, 1.5513, 1.5487, 1.5471, 1.547, 1.5449, 1.544, 1.5423, 1.5332, 1.5317, 1.5303, 1.5281, 1.5277, 1.5267, 1.5262, 1.526, 1.5016, 1.4966, 1.52, 1.4557, 1.3224, 1.2681, 1.2671, 1.3222, 1.3913, 1.0592, 1.3406, 1.2686, 1.3738, 1.4134, 1.3152, 1.0247, 0.7262, 1.0474, 1.1731, 0.7655, 1.2243, 0.8454, 0.7826, 0.7232, 0.5479, 0.6773, 1.0883, 0.3686, -0.0056, 0.5365, 1.0076, 0.5588, 0.3361, 0.1627, -0.2249, 0.3353, 0.4058, 0.5966, -0.4192, 0.3004, 0.7719, 0.1676, -0.6246, -0.0596, 1.6537, 1.6482, 1.6437, 1.6273, 1.6251, 1.6075, 1.6003, 1.5902, 1.5787, 1.5543, 1.5509, 1.549, 1.5444, 1.5439, 1.5368, 1.5285, 1.5272, 1.5222, 1.5212, 1.5199, 1.5179, 1.5153, 1.5079, 1.5078, 1.5025, 1.4996, 1.4992, 1.4988, 1.4979, 1.4978, 1.4743, 1.4953, 1.4871, 1.4452, 1.4707, 1.4196, 1.4697, 1.41, 1.4489, 1.3536, 1.2553, 1.4349, 1.3503, 1.2344, 1.245, 1.1606, 1.1469, 1.2022, 1.2552, 1.0357, 1.1155, 1.0612, 1.1019, 1.1125, 1.0802, 0.8946, 0.9916, 1.0076, 0.999, 0.9831, 0.3429, 0.7338, 0.9048, 0.6562, 0.7749, 0.0662, -0.3514, 0.0469, 0.1323, 2.1062, 2.0827, 2.0643, 2.0598, 2.0561, 2.0276, 2.025, 2.0234, 2.0192, 2.019, 2.0114, 2.0107, 2.0081, 2.0004, 1.9993, 1.9928, 1.9828, 1.9807, 1.9797, 1.972, 1.9709, 1.9694, 1.9668, 1.9603, 1.96, 1.9447, 1.9387, 1.9381, 1.9371, 1.9369, 1.923, 1.8739, 1.9159, 1.8282, 1.8938, 1.8461, 1.757, 1.8447, 1.8271, 1.8207, 1.5157, 1.7115, 1.4899, 1.6868, 1.6837, 1.8498, 1.2463, 1.8082, 1.4639, 0.9523, 1.0157, 0.9702, 1.2087, 1.1047, 0.9712, 1.13, 0.3757, 1.1926, 0.7987, 1.5527, -0.0207, 0.6666, 1.1042, 0.6138, 0.9257, -0.1508, 0.2785, 0.384, 0.3835, 0.3217, -0.8007, -0.4016, -0.3013, -0.1421, -0.6597, -0.1267, 2.2527, 2.2505, 2.2483, 2.2474, 2.2463, 2.2461, 2.2408, 2.2396, 2.2383, 2.2377, 2.2359, 2.2304, 2.2302, 2.2296, 2.2278, 2.2245, 2.2231, 2.2221, 2.2219, 2.2218, 2.2215, 2.221, 2.2203, 2.2176, 2.2175, 2.2155, 2.2126, 2.2124, 2.212, 2.2117, 1.8454, 2.1732, 1.7439, 1.601, 1.7606, 1.8432, 1.418, 1.1433, 1.7221, 1.2462, 1.529, 0.7028, 0.8633, 0.7797, 1.2627, 1.0776, 0.7647, 0.6188, 0.7241, 1.0858, 0.962, 0.7748, 1.1933, 0.251], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.6654, -6.1666, -6.2212, -6.514, -6.5688, -6.6821, -6.7011, -6.7954, -6.9396, -6.1932, -6.8603, -6.9856, -7.101, -6.6853, -7.1321, -7.2292, -7.2624, -7.2943, -5.7743, -7.3337, -7.3453, -7.3957, -7.3643, -7.4278, -7.4624, -6.6404, -7.4601, -6.5194, -7.5394, -7.4656, -5.7475, -5.9949, -6.6498, -6.7381, -4.9896, -6.2629, -5.0953, -6.2258, -6.2767, -6.2224, -6.7662, -5.5121, -6.1195, -4.6831, -5.0643, -5.592, -5.1766, -6.1954, -5.9881, -5.9576, -6.1738, -6.2609, -4.8246, -6.3743, -5.6545, -5.5785, -6.1728, -5.5773, -5.4461, -6.0995, -5.9201, -5.3376, -5.3181, -5.5383, -5.8885, -5.3943, -5.2782, -5.7154, -5.637, -5.6153, -5.4771, -5.714, -5.5149, -5.8681, -5.8575, -5.8278, -5.8448, -5.8031, -6.4231, -5.4456, -7.2922, -6.4114, -7.4981, -7.3163, -6.9483, -7.5839, -6.7072, -5.9212, -7.6813, -6.5418, -7.7414, -7.771, -6.0818, -7.8041, -7.8727, -7.8136, -6.7888, -7.7311, -7.9278, -6.319, -7.9632, -7.7731, -7.6917, -8.076, -8.0743, -8.1033, -8.1081, -8.1186, -6.741, -7.5292, -5.6491, -6.3412, -7.5594, -6.5738, -4.7961, -4.4758, -4.6667, -5.4785, -6.3338, -3.673, -5.9607, -5.583, -6.4175, -6.7317, -6.2802, -4.7547, -3.5739, -5.2889, -5.8269, -4.5948, -6.2132, -5.2114, -5.0887, -5.0928, -4.8159, -5.1027, -5.872, -4.6786, -4.08, -5.0616, -5.772, -5.1924, -4.9245, -4.7848, -4.4668, -5.0639, -5.3066, -5.5531, -5.2201, -5.5433, -5.703, -5.5594, -5.4325, -5.5788, -7.2237, -7.0991, -7.0697, -7.5943, -7.5968, -6.7345, -7.9051, -8.0019, -8.1007, -8.2441, -6.9547, -7.4361, -7.0607, -7.9281, -8.1026, -8.443, -4.3084, -7.0126, -8.4355, -8.4943, -6.7121, -8.5, -6.9176, -8.2082, -8.5815, -8.6085, -8.6112, -6.9784, -8.58, -7.4248, -4.4041, -6.9914, -6.7796, -4.7376, -6.6986, -5.2464, -6.8692, -5.045, -6.5529, -5.0222, -3.5525, -6.3889, -5.466, -4.5163, -4.9464, -4.4546, -4.4067, -4.8599, -5.2803, -3.9118, -4.6969, -4.5687, -4.8298, -4.8828, -4.7895, -3.9064, -4.6064, -4.8999, -5.2817, -5.2539, -3.7315, -4.7586, -5.2005, -4.6885, -5.2266, -4.2339, -4.5932, -5.1593, -5.228, -5.9764, -6.4636, -6.9807, -6.552, -6.9151, -7.0368, -7.4476, -7.4752, -7.52, -7.5169, -7.5807, -7.5416, -7.3563, -7.0607, -5.6925, -7.6778, -7.3825, -7.7789, -7.7682, -7.8529, -6.8529, -7.8935, -7.9206, -7.9066, -7.9134, -5.696, -7.1258, -4.5379, -7.1407, -6.737, -5.6426, -5.2451, -6.5852, -5.0686, -6.66, -6.158, -5.6015, -6.4361, -6.3707, -6.3859, -4.6273, -5.8233, -4.8766, -5.8662, -6.0964, -6.7783, -4.5337, -6.6778, -5.567, -4.0949, -4.3835, -4.2904, -4.9991, -4.8612, -4.7801, -5.1586, -3.6987, -5.2824, -4.7204, -5.992, -4.3208, -5.0773, -5.6184, -5.2022, -5.4933, -4.883, -5.1635, -5.3185, -5.3289, -5.3082, -5.0426, -5.2026, -5.2488, -5.3482, -5.4676, -5.4905, -4.1908, -4.5634, -4.8421, -4.9331, -5.0376, -5.0523, -5.4386, -5.5057, -5.5801, -5.608, -5.6959, -5.9263, -5.9334, -5.9555, -6.0204, -6.1158, -6.1703, -6.1981, -6.2045, -6.2077, -6.2076, -6.2296, -6.2483, -6.3209, -6.3225, -6.3727, -6.4397, -6.4379, -6.4545, -6.4588, -2.3964, -6.2039, -3.6981, -4.126, -4.8291, -5.1248, -3.7881, -2.9311, -5.0387, -4.2463, -4.9548, -3.5973, -3.9376, -3.9525, -4.7389, -4.6348, -4.6345, -4.6418, -4.8295, -5.1543, -5.4373, -5.4329, -5.5293, -5.5003]}, \"token.table\": {\"Topic\": [1, 3, 1, 2, 1, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 3, 1, 2, 3, 4, 5, 3, 3, 5, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 1, 2, 3, 4, 2, 3, 3, 2, 4, 5, 5, 5, 1, 2, 3, 4, 5, 5, 1, 1, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 5, 1, 3, 4, 1, 1, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 5, 5, 1, 2, 3, 4, 5, 1, 1, 1, 2, 4, 2, 3, 2, 1, 2, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 3, 1, 3, 1, 3, 4, 5, 2, 3, 1, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 5, 3, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 4, 5, 2, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 4, 5, 4, 1, 2, 4, 2, 5, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 4, 1, 4, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 2, 1, 2, 3, 4, 5, 5, 3, 4, 1, 2, 3, 4, 5, 3, 1, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 4, 2, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 4, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 3, 4, 5, 2, 3, 5, 2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 2, 1, 2, 3, 4, 1, 2, 3, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 1, 3, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 1, 4, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 3, 1, 3, 1, 3, 4, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 4, 1, 2, 3, 2, 4, 2, 1, 2, 1, 2, 4, 1, 2, 3, 4, 2, 4, 5, 1, 3, 3, 3, 1, 3, 1, 3, 1, 2, 3, 4, 5, 4, 1, 4, 1, 3, 4, 2, 4, 4, 2, 1, 4, 3, 5, 1, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 1, 4, 1, 2, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4], \"Freq\": [0.9562186354234847, 0.02124930300941077, 0.9900527452237063, 0.9310859871739823, 0.38008147797407443, 0.28777597618037065, 0.016289206198888906, 0.3094949177788892, 0.9493003256618763, 0.9064584914612233, 0.09064584914612232, 0.014423577327357892, 0.7163710072587753, 0.10096504129150524, 0.1586593506009368, 0.009615718218238594, 0.6653699493937311, 0.09415612491420722, 0.14437272486845107, 0.05021659995424385, 0.03766244996568289, 0.930710988343278, 0.15878068863716477, 0.7939034431858238, 0.20168508537400748, 0.025857062227436858, 0.6257409059039719, 0.04654271200938634, 0.09825683646426005, 0.9092793656260781, 0.0077716185096246, 0.050515520312559896, 0.027200664783686098, 0.8217871276597085, 0.7561917011461872, 0.016252215732078575, 0.22753102024910002, 0.10726462383171859, 0.1332681690030443, 0.5200709034265144, 0.9635561628790681, 0.9326974622353728, 0.9707103690506412, 0.9574935638125418, 0.3211877156262217, 0.27671557038566796, 0.09388563995228019, 0.30801078370309465, 0.10461695553598213, 0.7132974241089691, 0.10461695553598213, 0.0475531616072646, 0.038042529285811685, 0.04297513525990483, 0.6776848252523454, 0.046280914895282126, 0.2314045744764106, 0.0033057796353772946, 0.15369160720920655, 0.4429934560735953, 0.16725263137472476, 0.18533399692874905, 0.04972375527356682, 0.9916922947428451, 0.9868456593730329, 0.29007263968735675, 0.5689886393867383, 0.06693983992785156, 0.07809647991582683, 0.0729666692743937, 0.8026333620183307, 0.10945000391159054, 0.44089011201254086, 0.1427342089249233, 0.23154660558932003, 0.1744529220193507, 0.009515613928328219, 0.48628979840077147, 0.016963597618631563, 0.4919443309403153, 0.005654532539543854, 0.838693106237217, 0.10506862896350476, 0.05072278639617471, 0.8333029193657274, 0.014492224684621347, 0.8176544852958201, 0.7102948294962882, 0.9660571010715685, 0.22179680459130435, 0.7604461871701863, 0.9872764827306314, 0.9663371906444682, 0.9927439126605386, 0.3858775273679987, 0.1308435293948961, 0.34817684940675747, 0.0997959122503445, 0.03548299102234471, 0.9820793034177031, 0.9766776554522427, 0.9834929120986391, 0.9590415740268915, 0.010095174463440963, 0.020190348926881926, 0.9756913795308613, 0.26449402552854734, 0.07847624933264591, 0.57549249510607, 0.029065277530609595, 0.04941097180203631, 0.12390893119100632, 0.6795005904022927, 0.051961809854292974, 0.1438942426734267, 0.04188714077176391, 0.9215170969788061, 0.8325629430582621, 0.034690122627427586, 0.1156337420914253, 0.015417832278856706, 0.9594651200762215, 0.9694685743743483, 0.8823957909053175, 0.04456544398511705, 0.07130471037618727, 0.9684793242686984, 0.968566519580499, 0.973670122923107, 0.7090363211208425, 0.07334858494353542, 0.14669716988707085, 0.07334858494353542, 0.432163570380255, 0.06229384798273946, 0.49445741836299445, 0.011680096496763649, 0.04442264861211463, 0.04442264861211463, 0.8884529722422926, 0.987115855915266, 0.940868413098238, 0.9255218571280112, 0.08471834058439745, 0.0737869417993139, 0.5684327368243441, 0.05738984362168859, 0.21589512600539995, 0.9869270827002337, 0.9790641371908378, 0.19178808341711523, 0.7671523336684609, 0.023973510427139404, 0.1615983817551661, 0.8079919087758305, 0.9407561438919008, 0.05360683704061808, 0.9113162296905074, 0.9154862502840444, 0.04225321155157128, 0.01408440385052376, 0.01408440385052376, 0.04406599673360232, 0.1101649918340058, 0.837253937938444, 0.1977797841828039, 0.6472792936891765, 0.0179799803802549, 0.1258598626617843, 0.9303792506325073, 0.9212448901280412, 0.06580320643771723, 0.0562165987260935, 0.19113643566871788, 0.08994655796174959, 0.6633558649679032, 0.144890958339231, 0.821048763922309, 0.04101716601228937, 0.7639447169788895, 0.015381437254608514, 0.17432295555222982, 0.6794272463078131, 0.060914166910355665, 0.23428525734752179, 0.028114230881702614, 0.7382663699004826, 0.057341077273823884, 0.1576879625030157, 0.04300580795536792, 0.17260352117398534, 0.7374877722888464, 0.04707368759290509, 0.03138245839527006, 0.8531641535150262, 0.7389493126623692, 0.12132003640725465, 0.08271820664131, 0.05514547109420666, 0.6205465011788782, 0.157957291209169, 0.1541964033232364, 0.06393509406085411, 0.05944935235060362, 0.21798095861887992, 0.03963290156706908, 0.6539428758566398, 0.03963290156706908, 0.13228898075011433, 0.05291559230004573, 0.7672760883506631, 0.05291559230004573, 0.1773896954256165, 0.24144708544042245, 0.044347423856404125, 0.5420240693560504, 0.23075012130241077, 0.7307087174576341, 0.9607646795172, 0.8931167848793685, 0.06565702620513243, 0.007295225133903604, 0.6346845866496136, 0.08754270160684324, 0.2042663037493009, 0.984675856344733, 0.9981243836688745, 0.007332921565788729, 0.09532798035525347, 0.14421412412717832, 0.15643566007015955, 0.5988552612060796, 0.09271702000723976, 0.8344531800651578, 0.8460970515659889, 0.02001507646837998, 0.16012061174703984, 0.1000753823418999, 0.5604221411146394, 0.16012061174703984, 0.06843705904269, 0.08982363999353063, 0.3935130894954675, 0.08126900761319437, 0.36784919235445873, 0.9631804470256021, 0.07192189061625039, 0.8630626873950046, 0.07192189061625039, 0.9147811347880486, 0.08049547895330594, 0.8586184421685967, 0.053663652635537296, 0.8357919684026978, 0.09286577426696642, 0.9189637794676575, 0.991349983489975, 0.06285682571070363, 0.32571264231910063, 0.4857118350372553, 0.11999939453861601, 0.0028571284413956193, 0.10250456603210165, 0.2882940919652859, 0.12813070754012706, 0.17297645517917154, 0.30751369809630497, 0.041786929356117906, 0.20893464678058954, 0.7521647284101224, 0.1922751318235165, 0.41201813962182104, 0.39141723264073, 0.12360009409031573, 0.8652006586322101, 0.9167408458264604, 0.35726626538124934, 0.11908875512708311, 0.48176814574138166, 0.04330500186439386, 0.08811444665227454, 0.903173078185814, 0.036514162098881496, 0.9493682145709189, 0.01217138736629383, 0.09484222409292846, 0.1264562987905713, 0.7587377927434277, 0.04422482101589885, 0.884496420317977, 0.04422482101589885, 0.9727459737701479, 0.3079164287537454, 0.41681370233738707, 0.10514219518420576, 0.12391758718138535, 0.04506094079323104, 0.1319477022638617, 0.008796513484257449, 0.15833724271663407, 0.36065705285455535, 0.34306402588604046, 0.08426619918369073, 0.3948027480272917, 0.19271991850344083, 0.11625614517009183, 0.211445740544261, 0.9526871943058554, 0.02165198168876944, 0.02165198168876944, 0.9420892667532242, 0.5022589040962215, 0.1004517808192443, 0.2712198082119596, 0.12389052967706798, 0.0033483926939748103, 0.9659791878294962, 0.9106133712503671, 0.882476272572498, 0.054790968676649676, 0.18990051643611536, 0.2546534794176104, 0.1724670264026359, 0.32812318741584523, 0.7811732096355241, 0.9857250028249485, 0.9693185511016544, 0.10618837418394679, 0.12093675948727274, 0.5220928397377383, 0.16223223833658537, 0.08849031181995566, 0.9675179847573087, 0.019350359695146174, 0.9719680333400171, 0.019439360666800343, 0.019439360666800343, 0.05232234786878253, 0.05232234786878253, 0.8371575659005205, 0.7828997921054841, 0.05986695038521884, 0.11973390077043768, 0.2993347519260942, 0.514855773312882, 0.12381370389201986, 0.06190685194600993, 0.804789075298129, 0.14382325763055195, 0.01307484160277745, 0.06537420801388726, 0.7714156545638696, 0.41274583632411477, 0.2593358794602845, 0.24472540737801496, 0.08401021447304992, 0.9890587006221231, 0.09149526722699158, 0.8234574050429242, 0.945011919923851, 0.1301020420418001, 0.6805337583724929, 0.180141288980954, 0.3188150214201286, 0.07226473818856247, 0.5483618368426211, 0.05951213733175733, 0.3323463430233814, 0.3472275225617418, 0.1934553339986847, 0.12400982948633635, 0.14739765525196585, 0.7159314683666913, 0.02105680789313798, 0.1052840394656899, 0.15079939161470252, 0.37699847903675626, 0.058263401305680515, 0.4112710680400978, 0.17143774731702918, 0.22510521604236003, 0.5083501898704952, 0.0879550181887367, 0.005963052080592319, 0.13751609686027813, 0.8250965811616687, 0.9597136739915656, 0.8644518167786529, 0.879551141109311, 0.9735955018598731, 0.9979952999692262, 0.2511704797544032, 0.009660403067477046, 0.6955490208583474, 0.038641612269908185, 0.07185155336592594, 0.11723148180756338, 0.7903670870251853, 0.022689964220818717, 0.2026146100161393, 0.12663413126008707, 0.6331706563004353, 0.025241373082890803, 0.5517042973831847, 0.09255170130393295, 0.10216746247836754, 0.22837432789282155, 0.12374020258543365, 0.824934683902891, 0.05499564559352607, 0.7427134454016758, 0.23049727615914078, 0.025610808462126752, 0.932595344305891, 0.9063097976482535, 0.8265891004075747, 0.10572651284282933, 0.03844600467011976, 0.028834503502589818, 0.08858061586805306, 0.1328709238020796, 0.7972255428124776, 0.8972728616388441, 0.973242558362542, 0.7623743263499356, 0.9789585989973008, 0.058180254745426714, 0.9308840759268274, 0.12360169910463155, 0.04120056636821051, 0.7828107609959998, 0.4210266066685621, 0.06604338928134308, 0.144469914052938, 0.359110929217303, 0.012383135490251827, 0.5304734961063327, 0.058400751864917354, 0.3698714284778099, 0.03893383457661157, 0.9653607566796064, 0.9075857306616749, 0.4935287419895912, 0.14286358320751325, 0.06493799236705147, 0.2987147648884368, 0.15401372374540406, 0.05133790791513469, 0.8214065266421551, 0.9619283136688833, 0.031538633235045355, 0.19965732056235264, 0.10242161249627181, 0.633976816590847, 0.060934377054743985, 0.0025929522150954887, 0.0608870119511745, 0.26696612932438046, 0.11943221575038074, 0.327853141275555, 0.22481358258895198, 0.863000439122236, 0.2363249332332549, 0.530874850016732, 0.08562497580915032, 0.12672496419754248, 0.017124995161830064, 0.9873219382989223, 0.991479274901441, 0.29290939939088373, 0.5439745988687841, 0.04782194275769531, 0.05379968560240722, 0.06575517129183105, 0.15887879662916152, 0.8341136823030979, 0.9666621151091535, 0.9264360190522086, 0.03342031328889779, 0.143964426475252, 0.37533582616762134, 0.08483617988720209, 0.3624818595180453, 0.09423781595851882, 0.08077527082158757, 0.7404399825312193, 0.020193817705396893, 0.060581453116190676, 0.9784628355110043, 0.0508532781154452, 0.1017065562308904, 0.8136524498471231, 0.11593094550138673, 0.8810751858105392, 0.7095489017759453, 0.779310229527825, 0.23217744814542685, 0.6152702375853811, 0.011608872407271343, 0.13930646888725612, 0.058188309899473725, 0.0498756941995489, 0.7481354129932336, 0.1413144668987219, 0.8164697166315595, 0.9596664997488779, 0.9822717331802171, 0.27008084435070884, 0.5215354235737826, 0.1210707233296281, 0.07450506051054037, 0.04281868074856239, 0.2671070084791273, 0.1814696469820025, 0.31400365882279085, 0.19370355576730605, 0.10260585903074958, 0.05130292951537479, 0.718241013215247, 0.10260585903074958, 0.08262694252779237, 0.9088963678057161, 0.26811338325567136, 0.04998724094597262, 0.5998468913516715, 0.07725300873468496, 0.20272283698146687, 0.07336636005043563, 0.1892079811827024, 0.10232676533350232, 0.43247538556046267, 0.9857267896013906, 0.08451450396445864, 0.8451450396445864, 0.24742526272810508, 0.06747961710766502, 0.5323392016271352, 0.09747055804440503, 0.05623301425638752, 0.07992469617194738, 0.3330195673831141, 0.13986821830090793, 0.31303839334012723, 0.13320782695324565, 0.9828447127590398, 0.9697235027198403, 0.07615009894084179, 0.9138011872901016, 0.22027963811597906, 0.39437161017538186, 0.15988038250353317, 0.22027963811597906, 0.007105794777934808, 0.03879844023654365, 0.1551937609461746, 0.0775968804730873, 0.7371703644943293, 0.03265830744173717, 0.9470909158103781, 0.9580290294757755, 0.1709781557187603, 0.15957961200417628, 0.29636213657918453, 0.3647533988666886, 0.08175018278618681, 0.020437545696546704, 0.08175018278618681, 0.8175018278618681, 0.9420030585561873, 0.05233350325312151, 0.35101339111244595, 0.07179819363663667, 0.5424752408101438, 0.031910308282949634, 0.08072204946225087, 0.08072204946225087, 0.04036102473112543, 0.6457763956980069, 0.16144409892450173, 0.9638217146781531, 0.9024976831381163, 0.09376599305331078, 0.8554597103411157, 0.1176257101719034, 0.02138649275852789, 0.9168545389604825, 0.8547434811916536, 0.4249935353690498, 0.3300481710844748, 0.09494536428457495, 0.10398777993072494, 0.04521207823074998, 0.05729933081848315, 0.07639910775797754, 0.3947287234162173, 0.19736436170810864, 0.27376346946608615, 0.847368011642176, 0.972524430664016, 0.07026398686057117, 0.9134318291874253, 0.8940913103502098, 0.08706205600196931, 0.19899898514735842, 0.6964964480157545, 0.012437436571709901, 0.36041933773791124, 0.40997699667687404, 0.20724111919929897, 0.022526208608619452, 0.8064998734598088, 0.5292766401133535, 0.042006082548678846, 0.2772401448212804, 0.08401216509735769, 0.06720973207788616, 0.9451559667255814, 0.04974505088029376, 0.03167183474299618, 0.9501550422898853, 0.5719203063712456, 0.005295558392326347, 0.10591116784652695, 0.15357119337746408, 0.15886675176979043, 0.21934789172616176, 0.036557981954360295, 0.16451091879462132, 0.5849277112697647, 0.9715614857170517, 0.9674842960471105, 0.8543783241894563, 0.021182933657589824, 0.12003662405967568, 0.0035304889429316377, 0.0035304889429316377, 0.10980882647036291, 0.10980882647036291, 0.7686617852925404, 0.053988077030667936, 0.863809232490687, 0.0809821155460019, 0.037377431436195714, 0.14950972574478286, 0.78492606016011, 0.8656748119036457, 0.08244522018129959, 0.9210601839793764, 0.10741735783812359, 0.8593388627049887, 0.09969335751961593, 0.19938671503923186, 0.6812379430507088, 0.06500513502234323, 0.8125641877792904, 0.06500513502234323, 0.032502567511171615, 0.1562634852944478, 0.781317426472239, 0.9832313592589489, 0.11558661952899374, 0.866899646467453, 0.8128666490489769, 0.8775917349728335, 0.9729371636285284, 0.024527827654500716, 0.44604320492055505, 0.5522439679968777, 0.004416696580877839, 0.15237603204028544, 0.12734808474864437, 0.05300035897053407, 0.6625044871316759, 0.9304910115690582, 0.9798076307943466, 0.020412658974882224, 0.9085770609557992, 0.05678606630973745, 0.02271442652389498, 0.23653608188265726, 0.768742266118636, 0.9060738140920527, 0.8648297964780912, 0.09118899721600889, 0.9118899721600889, 0.9064821259002711, 0.9911715918071083, 0.9483595816081863, 0.07621450102311707, 0.15242900204623414, 0.20785773006304653, 0.07621450102311707, 0.4850013701471086, 0.8131762864281509, 0.10782642406548697, 0.09242264919898883, 0.13863397379848325, 0.06161509946599256, 0.6084491072266764, 0.9747629972817792, 0.4657308156253496, 0.16780007327678037, 0.2157429513558605, 0.08561228228407163, 0.06506533453589443, 0.04601129155726535, 0.9202258311453069, 0.886382500147508, 0.030992395110052726, 0.08058022728613709, 0.9589621737908918, 0.01712432453198021, 0.01712432453198021, 0.940099808939033, 0.024739468656290342, 0.024739468656290342, 0.012369734328145171, 0.9775144102078813, 0.012532236028306172, 0.9787390691398448, 0.8334117189852309, 0.912897671378371, 0.08192671409805893, 0.8484659219947326, 0.004793592779631257, 0.13661739421949085, 0.009587185559262515, 0.9689607516815401, 0.4858507604014628, 0.17955354188749711, 0.07129331810238856, 0.26404932630514283, 0.005256880855904224, 0.16296330653303095, 0.20501835338026472, 0.39952294504872105, 0.22604587680388163, 0.9358679151169009, 0.05737121318724297, 0.0035857008242026855, 0.7608669911302673, 0.8099912844430177, 0.9095610668292636, 0.06229870320748381, 0.024919481282993525, 0.9660309104013167, 0.882379245767708, 0.07328999786459336, 0.04187999877976764, 0.14657999572918673, 0.7433699783408756, 0.9510828968307095, 0.03908559849989217, 0.8885062284474368, 0.03702109285197653, 0.03702109285197653, 0.03702109285197653, 0.7089171533713154, 0.08543952662781326, 0.17549740604631914, 0.030019293139501958, 0.4459999007218157, 0.018978719179651733, 0.4459999007218157, 0.018978719179651733, 0.071170196923694, 0.32616373013615335, 0.03993841593503919, 0.6190454469931074, 0.01664100663959966, 0.10557872830948907, 0.12617945578451134, 0.44162809524578966, 0.07982781896571126, 0.24849627516745598, 0.154029073882471, 0.14786791092717216, 0.17251256274836752, 0.5236988512004014], \"Term\": [\"account\", \"account\", \"activate\", \"acts\", \"advertised\", \"advertised\", \"advertised\", \"advertised\", \"advertising\", \"alright\", \"alright\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazon\", \"amazon\", \"amazon\", \"amazon\", \"amazon\", \"amoled\", \"appearance\", \"appearance\", \"arrived\", \"arrived\", \"arrived\", \"arrived\", \"arrived\", \"att\", \"att\", \"att\", \"att\", \"attractive\", \"awaiting\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awsome\", \"bang\", \"bateria\", \"batery\", \"battery\", \"battery\", \"battery\", \"battery\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"beware\", \"bien\", \"big\", \"big\", \"big\", \"big\", \"bigger\", \"bigger\", \"bigger\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"box\", \"box\", \"box\", \"box\", \"brainer\", \"brand\", \"brand\", \"brand\", \"brand\", \"brilliant\", \"bubbles\", \"buck\", \"budget\", \"budget\", \"buen\", \"buena\", \"bueno\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"calidad\", \"called\", \"calling\", \"calls\", \"calls\", \"calls\", \"camara\", \"came\", \"came\", \"came\", \"came\", \"came\", \"camera\", \"camera\", \"camera\", \"camera\", \"cameras\", \"cameras\", \"card\", \"card\", \"card\", \"card\", \"cards\", \"cargador\", \"carrier\", \"carrier\", \"carrier\", \"carriers\", \"cdma\", \"celular\", \"charge\", \"charge\", \"charge\", \"charge\", \"charger\", \"charger\", \"charger\", \"charger\", \"charm\", \"charm\", \"charm\", \"compatible\", \"compra\", \"compre\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"connect\", \"connection\", \"cool\", \"cool\", \"cool\", \"cosmetic\", \"cosmetic\", \"crisp\", \"curved\", \"curved\", \"data\", \"data\", \"data\", \"data\", \"daughter\", \"daughter\", \"daughter\", \"decent\", \"decent\", \"decent\", \"decent\", \"defected\", \"defective\", \"defective\", \"delivery\", \"delivery\", \"delivery\", \"delivery\", \"dents\", \"dents\", \"described\", \"described\", \"described\", \"described\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"disappointed\", \"disappointed\", \"disappointed\", \"disappointed\", \"display\", \"display\", \"display\", \"display\", \"doa\", \"doesnt\", \"doesnt\", \"doesnt\", \"doesnt\", \"dont\", \"dont\", \"dont\", \"dont\", \"durable\", \"durable\", \"durable\", \"durable\", \"durable\", \"early\", \"early\", \"early\", \"early\", \"easy\", \"easy\", \"easy\", \"easy\", \"enjoying\", \"enjoying\", \"equipo\", \"evidence\", \"exactly\", \"exactly\", \"exactly\", \"exactly\", \"exactly\", \"excelent\", \"excelente\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"exceptional\", \"exceptional\", \"exelent\", \"expectations\", \"expectations\", \"expectations\", \"expectations\", \"expectations\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"extras\", \"exynos\", \"exynos\", \"exynos\", \"fabulous\", \"face\", \"face\", \"face\", \"facial\", \"facial\", \"facing\", \"false\", \"far\", \"far\", \"far\", \"far\", \"far\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"favorite\", \"favorite\", \"favorite\", \"features\", \"features\", \"features\", \"fiance\", \"fiance\", \"figuring\", \"fine\", \"fine\", \"fine\", \"fine\", \"finger\", \"finger\", \"fingerprint\", \"fingerprint\", \"fingerprint\", \"flawless\", \"flawless\", \"flawless\", \"fragile\", \"fragile\", \"fragile\", \"funciona\", \"galaxy\", \"galaxy\", \"galaxy\", \"galaxy\", \"galaxy\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"good\", \"good\", \"good\", \"good\", \"good\", \"google\", \"google\", \"google\", \"gorilla\", \"got\", \"got\", \"got\", \"got\", \"got\", \"gracias\", \"grandson\", \"grate\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greate\", \"gsm\", \"gusto\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hear\", \"hear\", \"help\", \"help\", \"help\", \"hesitant\", \"hesitant\", \"hesitant\", \"hiccups\", \"highly\", \"highly\", \"highly\", \"highly\", \"hoped\", \"hoped\", \"hoped\", \"husband\", \"husband\", \"husband\", \"husband\", \"im\", \"im\", \"im\", \"im\", \"imei\", \"inexpensive\", \"inexpensive\", \"intuitive\", \"iphone\", \"iphone\", \"iphone\", \"issues\", \"issues\", \"issues\", \"issues\", \"ive\", \"ive\", \"ive\", \"ive\", \"lasts\", \"lasts\", \"lasts\", \"lasts\", \"life\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"like\", \"likenew\", \"likenew\", \"likes\", \"liking\", \"lil\", \"llego\", \"locked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looks\", \"looks\", \"looks\", \"looks\", \"lots\", \"lots\", \"lots\", \"love\", \"love\", \"love\", \"love\", \"love\", \"loves\", \"loves\", \"loves\", \"loving\", \"loving\", \"loving\", \"luv\", \"mah\", \"make\", \"make\", \"make\", \"make\", \"marks\", \"marks\", \"marks\", \"meets\", \"mejor\", \"merchant\", \"message\", \"met\", \"met\", \"mint\", \"mint\", \"mint\", \"money\", \"money\", \"money\", \"money\", \"money\", \"months\", \"months\", \"months\", \"months\", \"movies\", \"neat\", \"need\", \"need\", \"need\", \"need\", \"nervous\", \"nervous\", \"nervous\", \"network\", \"network\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nicks\", \"note\", \"note\", \"note\", \"note\", \"note\", \"nuevo\", \"number\", \"ok\", \"ok\", \"ok\", \"ok\", \"ok\", \"packaged\", \"packaged\", \"pantalla\", \"penny\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfecto\", \"performs\", \"performs\", \"performs\", \"personal\", \"personal\", \"phoneno\", \"phonr\", \"pictures\", \"pictures\", \"pictures\", \"pictures\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"pleasure\", \"precio\", \"prepaid\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"price\", \"price\", \"price\", \"priced\", \"priced\", \"priced\", \"priced\", \"print\", \"print\", \"problems\", \"problems\", \"problems\", \"problems\", \"product\", \"product\", \"product\", \"product\", \"product\", \"producto\", \"prompt\", \"prompt\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"randomly\", \"rapido\", \"reader\", \"reader\", \"really\", \"really\", \"really\", \"really\", \"really\", \"reasonable\", \"reasonable\", \"reasonable\", \"reasonable\", \"recognition\", \"recognition\", \"recomiendo\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommended\", \"recommended\", \"recommended\", \"recommended\", \"refund\", \"refund\", \"refurbished\", \"refurbished\", \"refurbished\", \"refurbished\", \"reliable\", \"reliable\", \"reliable\", \"reliable\", \"reliable\", \"responding\", \"return\", \"return\", \"returned\", \"returned\", \"returned\", \"rocks\", \"rough\", \"samsung\", \"samsung\", \"samsung\", \"samsung\", \"samsung\", \"satisfied\", \"satisfied\", \"satisfied\", \"satisfied\", \"satisfied\", \"satisfy\", \"scam\", \"scanner\", \"scanner\", \"schedule\", \"scratches\", \"scratches\", \"scratches\", \"scratches\", \"screen\", \"screen\", \"screen\", \"screen\", \"selfie\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"send\", \"send\", \"sensor\", \"sensor\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shipping\", \"shipping\", \"shipping\", \"shipping\", \"shut\", \"si\", \"sim\", \"sim\", \"sim\", \"sim\", \"sim\", \"sister\", \"sister\", \"sister\", \"size\", \"size\", \"size\", \"skeptical\", \"skeptical\", \"skeptical\", \"sleek\", \"sleek\", \"slim\", \"slippery\", \"slippery\", \"smartphone\", \"smartphone\", \"smartphone\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"snapdragon\", \"snapdragon\", \"solo\", \"sooner\", \"sooner\", \"spanking\", \"splus\", \"sprint\", \"sprint\", \"star\", \"star\", \"stars\", \"stars\", \"stars\", \"stars\", \"stars\", \"starter\", \"stolen\", \"stolen\", \"store\", \"store\", \"store\", \"sturdy\", \"sturdy\", \"stylish\", \"surprisingly\", \"sweet\", \"sweet\", \"teenage\", \"telefono\", \"texts\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thankful\", \"thanks\", \"thanks\", \"thanks\", \"thanks\", \"thanks\", \"tiempo\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timely\", \"timely\", \"tmobile\", \"tmobile\", \"tmobile\", \"told\", \"told\", \"told\", \"tried\", \"tried\", \"tried\", \"tried\", \"turn\", \"turn\", \"unable\", \"unblocked\", \"unlock\", \"unlock\", \"unlocked\", \"unlocked\", \"unlocked\", \"unlocked\", \"unusable\", \"use\", \"use\", \"use\", \"use\", \"value\", \"value\", \"value\", \"value\", \"value\", \"verizon\", \"verizon\", \"verizon\", \"vertical\", \"vr\", \"waste\", \"waste\", \"waste\", \"wasted\", \"wide\", \"wife\", \"wife\", \"wife\", \"wife\", \"wifi\", \"wifi\", \"wont\", \"wont\", \"wont\", \"wont\", \"work\", \"work\", \"work\", \"work\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"working\", \"working\", \"working\", \"working\", \"works\", \"works\", \"works\", \"works\", \"works\", \"worth\", \"worth\", \"worth\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 4, 3, 1, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1138829557992961844921042155\", ldavis_el1138829557992961844921042155_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1138829557992961844921042155\", ldavis_el1138829557992961844921042155_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1138829557992961844921042155\", ldavis_el1138829557992961844921042155_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.180634 -0.057445       1        1  40.504022\n",
       "3      0.035948  0.102819       2        1  19.112855\n",
       "2      0.042429 -0.107411       3        1  18.059810\n",
       "0      0.004295  0.103036       4        1  11.862467\n",
       "4     -0.263305 -0.040999       5        1  10.460846, topic_info=      Category         Freq        Term        Total  loglift  logprob\n",
       "8870   Default  1358.000000       stars  1358.000000  30.0000  30.0000\n",
       "3981   Default  1606.000000       great  1606.000000  29.0000  29.0000\n",
       "3894   Default  1281.000000        good  1281.000000  28.0000  28.0000\n",
       "5289   Default   831.000000        love   831.000000  27.0000  27.0000\n",
       "5921   Default   771.000000         new   771.000000  26.0000  26.0000\n",
       "3125   Default   409.000000   excellent   409.000000  25.0000  25.0000\n",
       "10428  Default   776.000000       works   776.000000  24.0000  24.0000\n",
       "7066   Default   517.000000     product   517.000000  23.0000  23.0000\n",
       "766    Default   607.000000     battery   607.000000  22.0000  22.0000\n",
       "3121   Default   150.000000   excelente   150.000000  21.0000  21.0000\n",
       "5152   Default   670.000000        like   670.000000  20.0000  20.0000\n",
       "1058   Default   276.000000       brand   276.000000  19.0000  19.0000\n",
       "664    Default   307.000000     awesome   307.000000  18.0000  18.0000\n",
       "6523   Default   388.000000     perfect   388.000000  17.0000  17.0000\n",
       "6984   Default   490.000000       price   490.000000  16.0000  16.0000\n",
       "5956   Default   427.000000        nice   427.000000  15.0000  15.0000\n",
       "5266   Default   264.000000       looks   264.000000  14.0000  14.0000\n",
       "857    Default   302.000000        best   302.000000  13.0000  13.0000\n",
       "1743   Default   365.000000   condition   365.000000  12.0000  12.0000\n",
       "8866   Default   282.000000        star   282.000000  11.0000  11.0000\n",
       "5130   Default   291.000000        life   291.000000  10.0000  10.0000\n",
       "10422  Default   300.000000     working   300.000000   9.0000   9.0000\n",
       "1136   Default   103.000000       bueno   103.000000   8.0000   8.0000\n",
       "5296   Default   145.000000       loves   145.000000   7.0000   7.0000\n",
       "2813   Default   202.000000        easy   202.000000   6.0000   6.0000\n",
       "2327   Default   195.000000   described   195.000000   5.0000   5.0000\n",
       "3324   Default   350.000000         far   350.000000   4.0000   4.0000\n",
       "1265   Default   250.000000      camera   250.000000   3.0000   3.0000\n",
       "3331   Default   312.000000        fast   312.000000   2.0000   2.0000\n",
       "3180   Default   233.000000    expected   233.000000   1.0000   1.0000\n",
       "...        ...          ...         ...          ...      ...      ...\n",
       "9439    Topic5    17.741351      tiempo    18.466027   2.2175  -6.3225\n",
       "3941    Topic5    16.874125     gracias    17.598723   2.2155  -6.3727\n",
       "1318    Topic5    15.779271    cargador    16.503887   2.2126  -6.4397\n",
       "8450    Topic5    15.807683          si    16.537736   2.2124  -6.4379\n",
       "8682    Topic5    15.548266        solo    16.272874   2.2120  -6.4545\n",
       "1713    Topic5    15.481441      compre    16.207073   2.2117  -6.4588\n",
       "8870    Topic5   899.647265       stars  1358.481365   1.8454  -2.3964\n",
       "9453    Topic5    19.975687      timely    21.733795   2.1732  -6.2039\n",
       "3125    Topic5   244.770285   excellent   409.113881   1.7439  -3.6981\n",
       "664     Topic5   159.569462     awesome   307.650359   1.6010  -4.1260\n",
       "9354    Topic5    78.992664      thanks   129.838304   1.7606  -4.8291\n",
       "2277    Topic5    58.769402    delivery    88.941703   1.8432  -5.1248\n",
       "7066    Topic5   223.716855     product   517.948553   1.4180  -3.7881\n",
       "3981    Topic5   527.058651       great  1606.104110   1.1433  -2.9311\n",
       "8389    Topic5    64.052395    shipping   109.415230   1.7221  -5.0387\n",
       "6523    Topic5   141.481465     perfect   388.984983   1.2462  -4.2463\n",
       "9351    Topic5    69.659017       thank   144.329489   1.5290  -4.9548\n",
       "3894    Topic5   270.744096        good  1281.652680   0.7028  -3.5973\n",
       "10428   Topic5   192.638188       works   776.671601   0.8633  -3.9376\n",
       "5289    Topic5   189.790086        love   831.967418   0.7797  -3.9525\n",
       "3180    Topic5    86.450837    expected   233.791461   1.2627  -4.7389\n",
       "3331    Topic5    95.934034        fast   312.181215   1.0776  -4.6348\n",
       "5956    Topic5    95.962788        nice   427.020462   0.7647  -4.6345\n",
       "6984    Topic5    95.260775       price   490.440145   0.6188  -4.6418\n",
       "1743    Topic5    78.962944   condition   365.918404   0.7241  -4.8295\n",
       "190     Topic5    57.059835  advertised   184.171037   1.0858  -5.1543\n",
       "8089    Topic5    42.996353   satisfied   157.069897   0.9620  -5.4373\n",
       "10001   Topic5    43.186099       value   190.226872   0.7748  -5.4329\n",
       "3824    Topic5    39.219586        gift   113.681404   1.1933  -5.5293\n",
       "7250    Topic5    40.373454     quality   300.282655   0.2510  -5.5003\n",
       "\n",
       "[383 rows x 6 columns], token_table=       Topic      Freq         Term\n",
       "term                               \n",
       "67         1  0.956219      account\n",
       "67         3  0.021249      account\n",
       "100        1  0.990053     activate\n",
       "112        2  0.931086         acts\n",
       "190        1  0.380081   advertised\n",
       "190        3  0.287776   advertised\n",
       "190        4  0.016289   advertised\n",
       "190        5  0.309495   advertised\n",
       "194        1  0.949300  advertising\n",
       "303        2  0.906458      alright\n",
       "303        3  0.090646      alright\n",
       "320        1  0.014424      amazing\n",
       "320        2  0.716371      amazing\n",
       "320        3  0.100965      amazing\n",
       "320        4  0.158659      amazing\n",
       "320        5  0.009616      amazing\n",
       "322        1  0.665370       amazon\n",
       "322        2  0.094156       amazon\n",
       "322        3  0.144373       amazon\n",
       "322        4  0.050217       amazon\n",
       "322        5  0.037662       amazon\n",
       "338        2  0.930711       amoled\n",
       "437        2  0.158781   appearance\n",
       "437        3  0.793903   appearance\n",
       "500        1  0.201685      arrived\n",
       "500        2  0.025857      arrived\n",
       "500        3  0.625741      arrived\n",
       "500        4  0.046543      arrived\n",
       "500        5  0.098257      arrived\n",
       "574        1  0.909279          att\n",
       "...      ...       ...          ...\n",
       "10323      3  0.146580         wife\n",
       "10323      4  0.743370         wife\n",
       "10325      1  0.951083         wifi\n",
       "10325      2  0.039086         wifi\n",
       "10399      1  0.888506         wont\n",
       "10399      2  0.037021         wont\n",
       "10399      3  0.037021         wont\n",
       "10399      4  0.037021         wont\n",
       "10409      1  0.708917         work\n",
       "10409      2  0.085440         work\n",
       "10409      3  0.175497         work\n",
       "10409      4  0.030019         work\n",
       "10416      1  0.446000       worked\n",
       "10416      2  0.018979       worked\n",
       "10416      3  0.446000       worked\n",
       "10416      4  0.018979       worked\n",
       "10416      5  0.071170       worked\n",
       "10422      1  0.326164      working\n",
       "10422      2  0.039938      working\n",
       "10422      3  0.619045      working\n",
       "10422      4  0.016641      working\n",
       "10428      1  0.105579        works\n",
       "10428      2  0.126179        works\n",
       "10428      3  0.441628        works\n",
       "10428      4  0.079828        works\n",
       "10428      5  0.248496        works\n",
       "10443      1  0.154029        worth\n",
       "10443      2  0.147868        worth\n",
       "10443      3  0.172513        worth\n",
       "10443      4  0.523699        worth\n",
       "\n",
       "[779 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 4, 3, 1, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(model_LDA_tf, matrix_tfidfvect, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleouetd01\\anaconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(model_LDA_cv, doc_term_matrix_cv, count_vectorizer)\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV. Find out number of topics for LDA (tfIDF vectorized matrix is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleouetd01\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LatentDirichletAllocation(batch_size=128,\n",
       "                                                 doc_topic_prior=None,\n",
       "                                                 evaluate_every=-1,\n",
       "                                                 learning_decay=0.7,\n",
       "                                                 learning_method='batch',\n",
       "                                                 learning_offset=10.0,\n",
       "                                                 max_doc_update_iter=100,\n",
       "                                                 max_iter=10,\n",
       "                                                 mean_change_tol=0.001,\n",
       "                                                 n_components=10, n_jobs=None,\n",
       "                                                 perp_tol=0.1,\n",
       "                                                 random_state=None,\n",
       "                                                 topic_word_prior=None,\n",
       "                                                 total_samples=1000000.0,\n",
       "                                                 verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_components': [5, 7, 10, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define Search Param\n",
    "search_params = {'n_components': [5, 7, 10, 15], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(matrix_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -297422.38015523285\n",
      "Model Perplexity:  4924.579152343306\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(matrix_tfidfvect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Estimation of number of topics based on \"Samsung\" dataset\n",
    "\n",
    "- 2, 3, 5, 10 components: the minimum of 2 is \"recommended\" by GridSearchCV\n",
    "search_params = {'n_components': [2, 3, 5, 10], 'learning_decay': [.5, .7, .9]}                                              \n",
    "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 2}\n",
    "Best Log Likelihood Score:  -277760.92158545385\n",
    "Model Perplexity:  3345.039938342581\n",
    "\n",
    "- 3, 5 or 9 components: Here 3 topics - also minimum\n",
    "search_params = {'n_components': [3, 5, 9], 'learning_decay': [.5, .7, .9]}\n",
    "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 3}\n",
    "Best Log Likelihood Score:  -283679.74330586474\n",
    "Model Perplexity:  3960.19078360036\n",
    "\n",
    "- 5, 7, 10, 15 components: 5 topics - also minimum number given in the param list\n",
    "search_params = {'n_components': [5, 7, 10, 15], 'learning_decay': [.5, .7, .9]}\n",
    "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 5}\n",
    "Best Log Likelihood Score:  -297422.38015523285\n",
    "Model Perplexity:  4924.579152343306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use number of topics around 5 or 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "103px",
    "width": "206px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
